## 📌 절대 주소 지정 vs 상대 주소 지정
CPU가 메모리에서 데이터를 읽거나 쓰기 위해, 해당 데이터가 위치한 메모리 주소를 MAR에 지정해야 한다.

> CPU는 명령어에서 필요한 메모리 주소를 MAR에 저장하고, MAR에 저장된 주소는 주소 버스를 통해 메모리로 전달된다. 메모리는 전달된 주소를 기반으로 해당 메모리 위치에 접근하여 데이터를 읽어온다.

메모리 주소는 **절대 주소**(**absolute address**)와 **상대 주소**(**relative address**)로 나뉜다.

<img width=500 src="https://github.com/user-attachments/assets/b30bb318-86f6-48f6-9aad-b8707bf64efe">

### 절대 주소 지정
- **실제 메모리의 주소 번지**를 지정하는 방식
- MAR에 저장되는 메모리의 실제 주소를 의미한다.

### 상대 주소 지정
- 메모리 공간에서 **사용자 영역이 시작되는 주소 번지를 0번지로 변경**하여 지정하는 방식
- **프로세스 입장에서 메모리 공간을 바라본 주소**이며, 절대 주소와 관계없이 항상 0번지부터 시작한다.

### 왜 이렇게 나뉘는가?
- **사용자가 절대 주소를 사용하면?**
  - 프로세스가 **운영체제 영역을 매번 확인해야 하는 불편함**이 존재한다.   
    (프로세스는 운영체제 영역에 접근해서는 안되며, 그로 인해 알 필요도 없다.)
  - 프로세스가 **운영체제 영역에 접근할 수 있다는 위험**이 존재한다.
- **사용자가 상대 주소를 사용하면?**
  - 메모리 주소가 항상 0번지부터 시작하기 때문에, 프로세스는 운영체제 영역을 확인할 필요 없다.
  - 사용자 영역 내에서만 유효한 주소를 생성하기 때문에, 운영체제는 프로세스가 사용할 수 있는 메모리 영역을 할당하고, 이 영역 외부에 있는 메모리 주소에 접근할 수 없도록 한다.

### 상대 주소 → 절대 주소 변환 과정
1. 프로그램이 메모리에 올라갈 때, 운영체제는 해당 프로그램이 시작하는 메모리 위치를 **기준 주소(Base Address)로 설정**한다.
2. 프로세스가 특정 상대 주소에 위치한 데이터를 요청하면, 운영체제는 기준 주소에 상대 주소를 더하여 절대 주소로 변환한다.

### 절대 주소 → 상대 주소 변환 과정
1. 실행 중인 프로그램에 오류가 발생할 때, 디버거는 오류가 발생한 메모리의 절대 주소를 알린다.
2. 이 절대 주소에서 기준 주소를 빼 상대 주소로 변환하여, 실제 코드에서 문제가 발생한 위치를 찾는다.

## 📌 메모리 분할
- 하나의 프로그램을 여러 개의 구역으로 나누어 메모리에 적재하는 방식
- 프로그램의 일부분만 메모리에 적재함으로써, **메모리 공간을 효율적으로 활용**할 수 있다.
- 각 구역마다 접근 권한을 설정하여 **프로그램을 보호**할 수 있다.
- 여러 프로세스가 **같은 프로그램의 구역을 공유**하여 메모리 사용량을 줄일 수 있다.   
  ex) 웹 브라우저는 각 탭이 별도의 프로세스로 실행된다. 그러나 모든 탭이 동일한 브라우저 코드를 실행하므로, 메모리 구역이 모든 탭 프로세스 간에 공유된다.
    
### 연속 할당 방식
- 비어 있는 메모리 공간에 프로세스를 연속적으로 할당하는 방식
- 물리적인 메모리를 일정한 크기로 미리 분할하는지 여부에 따라 고정 분할 방식과 가변 분할 방식으로 나뉜다.

- #### 고정 분할 방식
  <img width=500 src="https://github.com/user-attachments/assets/b6b8b9ce-dc8b-439e-9b04-addb3a34badf">

  - 메모리를 일정한 크기로 미리 나누어 관리하는 방식
  - 메모리를 일정한 크기로 나누어 관리하므로 **메모리 관리가 수월**하다.
  - 각 분할 구역에는 하나의 프로세스만 할당할 수 있기 때문에, 동시에 메모리에 올릴 수 있는 프로세스 수가 고정된다. 이는 **유연성을 떨어뜨린다**.
  - **외부, 내부 단편화가 발생할 수 있다.**

- #### 가변 분할 방식
  <img width=500 src="https://github.com/user-attachments/assets/7fdaffbf-9fc1-4112-bae8-5e1cea157193">

  - 메모리에 적재되는 프로세스의 크기에 따라 분할의 크기와 개수가 동적으로 변하는 방식
  - 각 프로세스에게 필요한 만큼의 공간만 할당하기 때문에 **내부 단편화가 발생하지 않는다.**
  - 메모리에 있는 프로세스가 종료될 때, 그 공간의 크기가 새롭게 할당할 프로세스의 크기보다 작을 경우 **외부 단편화가 발생한다.**
  - 프로세스를 메모리에 할당할 때 어떤 위치에 할당할 것인지 결정해야 하므로, **메모리 관리가 번거롭다**.   
    이를 결정하는 방법에는 3가지가 존재한다.
    - **최초 적합(First fit)**
      - 운영체제가 메모리 내의 빈 공간을 순서대로 탐색하다가 적재 가능한 공간을 발견하면, 즉시 해당 공간에 프로세스를 배치하는 방식
      - 탐색 빈도가 감소하여 빠른 할당이 가능하다.
    - **최적 적합(Best fit)**
      - 운영체제가 메모리 내의 빈 공간을 모두 탐색한 후, 적재 가능한 공간 중 최소 크기의 공간에 프로세스를 배치하는 방식
      - 탐색 빈도가 증가하여 시간적 오버헤드가 발생한다.
    - **최악 적합(Worst fit)**
      - 운영체제가 메모리 내의 빈 공간을 모두 탐색한 후, 적재 가능한 공간 중 최대 크기의 공간에 프로세스를 배치하는 방식
      - 탐색 빈도가 증가하여 시간적 오버헤드가 발생한다.

- #### 버디 시스템
  - 메모리 블록을 2의 제곱수크기로 분할하는 방식
  - 2의 제곱 크기 단위로 메모리를 분할하고 병합하기 때문에, **메모리 할당과 해제가 상대적으로 빠르다.**
  - 인접한 같은 크기의 블록을 병합함으로써 **외부 단편화를 줄일 수 있다**.
  - 2의 제곱 크기로만 메모리를 관리하기 때문에 **내부 단편화에 취약**하다.   
    ex) 257byte가 필요한 경우, 2의 제곱 단위로 맞추기 위해 512(=2^9)byte를 할당해야 한다.
  - **동작 원리**

    <img width=500 src="https://github.com/user-attachments/assets/bea744fd-a905-43d2-a7df-95a7620935eb">

### 불연속 할당 방식
- 하나의 프로세스를 메모리의 여러 위치에 분산 할당하는 방식
- 하나의 프로그램을 분할하는 기준에 따라 동일한 크기로 나누어 메모리에 올리는 **페이징** 기법과 크기는 일정하지 않지만 의미 있는 단위로 나누어 메모리에 올리는 **세그멘테이션** 기법이 있다.

## 📌 내부 단편화 vs 외부 단편화
### 내부 단편화(Internal Fragmentation)
- 모든 프로세스가 페이지 크기에 딱 맞게 잘리지 않아 메모리가 낭비되는 현상   
  ex) 크기가 10MB인 메모리 공간에 7MB 크기의 프로세스를 할당할 경우 3MB가 낭비된다.
    
### 외부 단편화(External Fragmentation)
- 프로세스를 할당하기 어려울 만큼 작은 메모리 공간들로 인해 메모리가 낭비되는 현상   
  ex) 프로세스들이 연속적으로 할당되는 경우, 빈 공간의 총 크기가 50MB이더라도 각 빈 공간의 크기가 20MB, 30MB라면 50MB 크기의 프로세스를 적재할 수 없다.
- 해결 방법으로는 **메모리 압축**(**Compaction**)과 **가상 메모리**(**Virtual memory**)가 있다.

## 📌 Coalescing vs Compaction
- 가변 분할 방식에서 발생할 수 있는 외부 단편화를 해결하기 위해 사용되는 기법

### Coalescing(통합)
<img width=500 src="https://github.com/user-attachments/assets/7cf949b4-4612-4557-b0e5-9f48b4d3a22e">

- **인접한 가용 공간을** **병합하여** 더 큰 연속된 가용 공간을 만드는 기법
- 특정 프로세스의 메모리 해제 시 인접한 가용 공간을 확인하여 병합이 가능하면 하나의 큰 가용 공간으로 병합한다.
- 프로세스를 재배치할 필요가 없어 **메모리 관리 비용이 작다.**

### Compaction(압축)
<img width=500 src="https://github.com/user-attachments/assets/ab41468e-c34d-4a5f-907b-39fde0011e9b">

- **여러 가용 공간을 한 곳으로 이동시켜** 하나의 큰 가용 공간은 만드는 기법
- 프로세스 재배치가 필요해 **메모리 관리 비용이 크다.**
- 메모리를 압축하는 동안 시스템은 하던 일을 중지하기 때문에 **비효율적**이다.
- 시간이 많이 걸리기 때문에, 실시간 시스템에서는 일반적으로 사용되지 않는다.

## 📌 페이징
<img width=500 src="https://github.com/user-attachments/assets/0fc1413c-af60-497a-87b7-731578daf9f0">

- 메모리의 물리 주소 공간을 **프레임(Frame)** 단위로 자르고, 프로세스의 논리 주소 공간을 **페이지(Page)** 단위로 일정하게 자른 뒤 각 페이지를 프레임에 할당하는 기법
- 페이징에서 스와핑은 프로세스 전체가 아닌 페이지 단위로 이루어진다.
- 프로세스를 이루는 페이지들 중 실행에 필요한 일부 페이지만 메모리에 적재하고, 나머지는 디스크에 남겨놓을 수 있다. 이를 통해 물리 메모리 크기보다 더 큰 프로세스를 실행할 수 있다.   
  <img width=500 src="https://github.com/user-attachments/assets/6db65e4b-4e6b-4fe3-8759-1186522ea895">
    
- 프로세스의 주소 공간과 물리적 메모리가 모두 같은 크기의 페이지 단위로 나누어지기 때문에 **외부 단편화가 발생하지 않는다.**
- 프로그램의 크기가 항상 페이지 크기의 배수가 된다는 보장이 없기 때문에, 프로세스의 주소 공간 중 제일 마지막에 위치한 페이지에서는 **내부 단편화가 발생할 수 있다.**   
  ex) 페이지와 프레임의 크기가 4KB라고 가정하면, 프로세스가 5KB의 데이터를 필요로 할 경우 2개의 페이지가 필요하다. 첫 번째 페이지는 4KB를 모두 사용하지만, 두 번째 페이지는 1KB만 사용되고 나머지 3KB는 사용되지 않는다. 이때, 사용되지 않는 3KB가 내부 단편화로 남게 된다.    
- 프로세스가 메모리에 불연속적으로 배치되기 때문에, CPU 입장에서 다음 실행할 명령어의 위치를 찾기 어렵다. 이를 해결하기 위해 **페이지 테이블**을 사용한다.

### 페이지 테이블
<img width=500 src="https://github.com/user-attachments/assets/375cfbed-e69d-4d1f-b527-db2990540f48">

- 주소 변환을 위해 프로세스의 페이지 정보를 저장하는 자료구조
- 각 프로세스마다 페이지 테이블이 존재하며, 테이블은 프로세스가 가질 수 있는 페이지 수만큼 엔트리를 가지고 있어야 한다.   
  <img width=500 src="https://github.com/user-attachments/assets/87284cbc-3dd4-4a2f-aa8d-b5611405846e">

- CPU 내의 **페이지 테이블 베이스 레지스터(PTBR)**는 각 프로세스의 페이지 테이블이 적재된 주소를 가리킨다.   
  <img width=500 src="https://github.com/user-attachments/assets/30eb3ee0-b0ff-49d3-83fd-d42a56baa8e7">
    
- 페이지 테이블을 메모리에 적재하면 메모리를 2번 접근해야 하기 때문에(페이지 테이블에 접근하기 위해 1번 + 프레임에 접근하기 위해 1번), CPU 곁에 (일반적으로 MMU 내에) **TLB**를 위치치킨다.   
  <img width=500 src="https://github.com/user-attachments/assets/33841177-60e9-4bf9-ba83-30e68c2529ea">

  - **TLB(Translation Lookaside Buffer)**: 페이지 테이블의 일부 내용을 저장하는 고속 주소 변환용 하드웨어 캐시
  - 참조지역성에 따라 주로 최근에 사용된 페이지 위주로 저장한다.
  - 주소 변환 정보는 프로세스마다 다르기 때문에, 문맥 교환이 이루어지면 TLB 내용은 모두 지워져야 한다.
  - TLB에서는 프로세스의 모든 페이지 정보를 가지고 있지 않기 때문에, 페이지 번호와 이에 대응하는 프레임 번호가 쌍으로 저장되어 있다.   
    따라서 TLB를 통한 주소 변환을 위해서는 TLB의 엔트리를 모두 탐색해야 하는 오버헤드가 발생한다.   
    이러한 오버헤드를 줄이기 위해 TBL 구현에는 일반적으로 병렬 탐색(TLB 내의 모든 항목을 동시에 탐색)이 가능한 연관 레지스터를 사용한다.
  - **MMU(Memory Management Unit)**: CPU가 코드를 실행하며 가상 메모리 주소에 접근할 때 가상 메모리 주소를 실제 물리적인 주소로 변환해주는 하드웨어 장치
 
### 주소 변환
- 페이징 시스템에서는 모든 논리 주소가 기본적으로 **페이지 번호**와 **변위(offset)**로 구성된다.
  <img width="427" alt="image" src="https://github.com/user-attachments/assets/2fbbb245-3b3a-48c1-8a3d-3735eaca94bd">  

  - **페이지 번호**: 접근하고자 하는 페이지 번호
  - **변위**: 접근하려는 주소가 프레임의 시작 번지로부터 떨어져 있는 거리
- 페이지 번호는 페이지 테이블의 접근 인덱스로 사용된다.
- ex) CPU가 `<<페이지 번호: 5, 변위: 2>>`에 접근하고자 하는 경우
  <img width=500 src="https://github.com/user-attachments/assets/31706184-0eb0-4e61-a363-b7f3cd1c1308">
    
  페이지 테이블을 보면, 5번 페이지에 해당하는 프레임 번호가 1임을 알 수 있다.   
  이때 변위가 2이므로, 1번 프레임의 시작 번지인 8번지로부터 2만큼 떨어진 10번지에 접근한다.

### 페이지 테이블 엔트리에 있는 정보
- 페이지 테이블 엔트리에는 페이지 번호, 프레임 번호 뿐만 아니라, 다른 중요한 정보도 존재한다.
  - #### 유효 비트(Valid bit)
    - 현재 페이지가 메모리에 있는지 디스크에 있는지 알려주는 비트   
      즉, 현재 페이지에 접근 가능한지 알려주는 비트
      - `1`: 메모리에 위치
      - `0`: 보조기억장치에 위치
    - CPU가 유효 비트 `0`인 페이지에 접근하려 하면 **페이지 폴트**(**Page fault**)가 발생한다.
  - #### 보호 비트(Protection bit)
    - 페이지 접근 권한을 제한하여 페이지를 보호하는 비트
      - `1`: 읽기/쓰기 모두 가능
      - `0`: 읽기만 가능
    - ex) 프로세스의 코드 영역은 읽기 전용 영역이므로, 해당 페이지가 코드 영역이라면 보호 비트는 `0`으로 설정된다.
    - 3개의 비트를 활용하여 더 세심하게 구현할 수 있다.            
      <img width=500 src="https://github.com/user-attachments/assets/54b30743-49d7-46c0-a9c1-72c34c21c1b1">
            
  - #### 참조 비트(Reference bit)
    - CPU가 현재 페이지에 접근한 기록이 있는지 나타내는 비트
      - `1`: 메모리 적재 이후 CPU가 읽거나 쓴 페이지
      - `0`: 한번도 읽거나 쓴 기록이 없는 페이지
  - #### 수정 비트(Modified bit)
    - 해당 페이지의 수정 여부를 나타내는 비트
      - `1`: 수정된 기록이 있음
      - `0`: 수정된 기록이 없음
    - Dirty bit라고도 부른다.   

    > CPU가 접근하지 않았거나 읽기만 했던 페이지는 메모리에 저장된 내용과 디스크에 저장된 내용이 동일하다.   
    > 이런 페이지는 스왑 아웃될 때 디스크에 변경된 값을 기록할 필요 없이, 메모리에 새로운 페이지로 덮어쓰기만 하면 된다.   
    > 그러나 수정한 기록이 있는 페이지는 스왑 아웃될 때 보조기억장치에 변경된 값을 기록해야 한다.

## 📌 세그멘테이션
<img width=500 src="https://github.com/user-attachments/assets/26e692c3-2ffe-474a-b1db-3938c5abd8b6">

- 프로세스의 주소 공간을 **세그먼트(Segment)** 단위로 나눈 뒤 각 세그먼트를 메모리에 배치하는 기법
- 일반적으로 코드, 데이터, 스택 등의 기능 단위로 세그먼트를 정의한다.
- 각 세그먼트는 의미를 가질 수 있는 논리적인 단위이므로
  - 크기가 일정하지 않다.
  - 공유와 보안 측면에서 페이징 기법에 비해 효과적이다.
- 페이징 기법과 달리 세그먼트의 크기가 일정하지 않기 때문에, **외부 단편화와 동적 할당 문제가 발생**한다.
- 페이징과 비슷하게 논리 주소는 `<<세그먼트 번호, offset>>`으로 구성된다.
- 각 프로세스마다 주소 변환을 위한 세그먼트 테이블을 사용하며, 테이블의 각 항목은 기준점(base)과 한계점(limit)을 가지고 있다.
  - **기준점(base)**: 물리적 메모리에서 세그먼트의 시작 위치
  - **한계점(limit)**: 세그먼트의 길이 (각 세그먼트의 길이가 일정하지 않기 때문에 필요함)
- 논리 주소를 물리 주소로 변환하기 전에 두 가지 사항을 확인하며, 모두 만족하면 주소 변환 작업이 수행된다.
  1. 요청된 세그먼트 번호가 STLR(Segment Table Length Register)에 저장된 값보다 작은 값인지 확인하고, 작은 값이라면 예외 상황을 발생시킨다.
  2. 논리 주소의 offset 값이 그 세그먼트의 길이보다 작은 값인지 확인한다.
 
## 📌 가상 메모리
<img width=500 src="https://github.com/user-attachments/assets/3832c3ec-d02d-489b-90d3-d65f386db09c">

- 각 프로세스마다 가상 메모리를 할당하는 메모리 관리 기법
- 가상 메모리 공간 중 일부는 실제 메모리에 적재 되거나, 디스크의 스왑 영역에 존재할 수 있다.
- 메모리의 연장 공간으로 디스크의 스왑 영역이 사용될 수 있기 때문에 프로그램 입장에서는 물리적 메모리 크기에 대한 제약을 생각할 필요가 없어진다.
- 프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 가상메모리 기법은 요구 페이징 방식과 요구 세그멘테이션 방식으로 구현될 수 있다.   
  요구 세그멘테이션 방식도 페이지드 세그먼테이션 기법을 사용하는 경우가 대부분이기 때문에 실질적으로 요구 페이징 기법만이 사용된다고 할 수 있다.

### 가상 주소와 물리 주소(실주소)
- **가상 주소(Virtual Address)**
  - 프로세스가 참조하는 논리적인 메모리 주소
  - 가상 메모리 시스템에서 프로세스는 물리 주소 대신 가상 주소를 사용하여 메모리에 접근한다.
  - 운영체제는 각 프로세스마다 고유한 가상 주소 공간을 제공하므로, 프로세스는 자신만의 독립된 메모리 공간을 가지는 것처럼 동작할 수 있다.
- **물리 주소(Physical Address)**
  - 실제 메모리 내에서의 물리적인 위치를 나타내는 주소
  - 메모리 하드웨어가 사용하는 주소로, CPU가 데이터를 읽거나 쓸 때 실제로 접근하는 메모리 위치를 가리킨다.

### 가상 주소 → 물리 주소(실주소) 변환 과정
1. 프로세스가 메모리에 있는 데이터를 읽거나 쓸 수 있도록 가상 주소를 생성한다.
2. CPU는 먼저 TLB에 해당 가상 주소의 페이지 번호가 존재하는지 확인한다.
3. TLB 미스가 발생하면 PTBR을 확인하여, 실행 중인 프로세스의 페이지 테이블 시작 주소를 가져온다.
4. 페이지 번호를 사용하여 페이지 테이블을 조회한 뒤 물리적 메모리 위치(프레임 번호)를 가져온다.
5. 프레임 번호와 offset을 활용하여 물리 주소를 계산한다.
6. 메모리 접근하여, 계산한 물리 주소에 해당하는 위치의 데이터를 읽거나 쓴다.

## 📌 Swapping
- 메모리 내 현재 실행 상태가 아닌(대기 상태 or 오랫동안 사용되지 않은) 프로세스를 일시적으로 스왑 영역에 보내고(swap out), 그 프로세스가 있던 공간에 다른 프로세스를 적재하는(swap in) 방식
  - **스왑 영역(swap space)**: 메모리에서 쫓겨난 프로세스들이 위치하는 디스크 내의 일부 영역
  - **스왑 아웃(swap out)**: 실행 상태가 아닌 프로세스를 메모리에서 스왑 영역으로 보내는 작업
  - **스왑 인(swap in)**: 디스크에 있는 프로세스를 메모리에 적재하는 작업
- swap out된 프로세스가 다시 swap in 될 때는 처음 물리주소와 다른 주소에 적재될 수도 있다.

### 동작 원리
<img width=500 src="https://github.com/user-attachments/assets/34866609-650c-4d9e-9215-74fd8c2a75c1">

1. 스와퍼(swapper)라고 불리는 중기 스케줄러에 의해 **스왑 아웃할 프로세스를 선정**한다.   
   일반적으로, 대기 상태이거나 오랫동안 실행되지 않은 프로세스가 선정된다.   
   이러한 프로세스는 메모리에서 디스크로 이동해도 다른 프로세스의 수행에 영향을 미치지 않는다.
2. 선정된 프로세스의 메모리 공간을 디스크 내의 스왑 영역에 저장한다.    
   이 과정에서 프로세스의 메모리 상태가 디스크에 기록되며, 프로세스가 다시 메모리에 적재될 때 복원된다.
3. 스왑 아웃된 프로세스가 있던 메모리 공간에 새로운 프로세스가 적재된다.
4. 스와핑된 프로세스가 다시 필요할 때, 운영체제는 해당 프로세스를 디스크에서 메모리로 다시 가져온다.

### 장점
- 물리적인 메모리를 늘리지 않고도 많은 프로세스를 동시에 실행할 수 있다. 이를 통해 **비용을 절감**하면서 **메모리 활용도를 증가**시킨다.

### 단점
- 스와핑이 자주 발생할수록 디스크 I/O 작업이 많이 발생하기 때문에, I/O 오버헤드가 증가하고 성능이 저하된다. (메모리 접근 속도 >>> 디스크 접근 속도)
- 스와핑을 반복적으로 수행하다 보면, 메모리 내에 작은 가용 블록들이 생성되어 외부 단편화가 발생할 수 있다.

## 📌 페이지 교체 알고리즘
- 메모리가 가득 찬 상태에서 페이지 폴트 발생 시, 요청된 페이지를 메모리에 적재하기 위해 디스크로 내보낼 페이지를 결정하는 알고리즘
- 일반적으로, 좋은 알고리즘 == 페이지 폴트 발생 횟수가 적은 알고리즘
  - 페이지 폴트 발생 횟수는 **페이지 참조열**을 통해 알 수 있다.
    - **페이지 참조열(Page reference string)**: CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 페이지열   
      ex) `2 2 2 3 5 5 5 3 7` → `2 3 5 3 7`
    - 중복된 페이지를 참조하는 행위는 페이지 폴트를 발생시키지 않는다.   
      ex) CPU가 특정 페이지에 10번 연속으로 접근한다고 해서 1번 접근하는 것보다 페이지 폴트 발생 횟수가 더 많지 않다.

### FIFO(First In First Out)
<img width=500 src="https://github.com/user-attachments/assets/b12f4281-be63-4e7b-942a-b8b26b32071a">

- 메모리에 적재된 페이지 순서대로 교체하는 방식
- 구현 과정이 간단하다.
- **페이지의 향후 참조 가능성을 고려하지 않아** 비효율적인 상황이 발생할 수 있다.   
  ex) 자주 참조되는(실행 내내 사용되는) 페이지가 먼저 적재되었다는 이유로 교체될 수 있다.

### LRU(Least Recently Used)
<img width=500 src="https://github.com/user-attachments/assets/2a1c005c-75e8-49bc-82e5-d29ac738eac7">

- 가장 오랫동안 사용되지 않은 페이지를 교체하는 방식
- 페이지마다 마지막으로 사용한 시간을 바탕으로, 최근 참조 횟수가 가장 적은 페이지를 교체한다.
- 페이지 접근 시간이나 참조 비트를 유지하기 위한 추가 공간이 필요하기 때문에 **불필요한 메모리 낭비가 발생**한다.
- **구현 방법**
  - 연결 리스트를 사용하며, `O(N)`의 시간복잡도를 가진다.
  - 페이지들을 참조 시간 순서대로 연결 리스트에 나열하며, 앞쪽으로 갈 수록 오래전에 참조한 페이지고, 뒤쪽으로 갈 수록 최근에 참조한 페이지다.
  - 새로운 페이지가 메모리에 적재되거나 기존에 있던 페이지가 다시 참조되면,
    - 연결 리스트 가장 앞에 있던 페이지를 디스크에 보낸다.
    - 새로운 또는 다시 참조된 페이지를 연결 리스트의 가장 뒤로 이동시킨다.
    
    > ### 우선순위 큐를 사용해서 구현할 수도 있지 않을까?
    > 우선순위 큐는 요소를 우선순위에 따라 정렬하므로, LRU 알고리즘에서 오래된 페이지를 쉽게 추적할 수 있다. 하지만 효율성과 복잡성 문제로 인해 연결 리스트로 구현하는 것이다.
    > - **효율성 문제**: 페이지 참조 시 우선순위 큐에서 페이지를 찾아 우선순위를 업데이트하는 과정(`O(log(N)`)이 필요한데, LRU 알고리즘에서는 페이지 참조가 빈번하게 발생하므로 성능이 저하된다.
    > - **복잡성 문제**: 각 페이지에 대해 추가적인 우선순위 값을 관리해야 하므로 복잡성이 증가한다.

### LFU(Latest Frequently Used)
<img width=500 src="https://github.com/user-attachments/assets/ab567c45-cb2d-4d3e-9b36-f92b9d9eee49">

- 사용 빈도가 적은 페이지를 교체하는 방식
- 페이지 사용 빈도를 바탕으로 가장 오래된 동시에 빈도가 적은 페이지 교체
- 페이지 접근 횟수(빈도)를 나타내기 위한 추가 공간이 필요하기 때문에, **불필요한 메모리 낭비가 발생**한다.
- 페이지 참조 횟수 계산 방식에 따라 2가지 방식으로 나뉜다.
  - **Incache-LFU**: 페이지가 메모리에 적재된 시점부터의 참조 횟수를 카운트하는 방식
  - **Perfect-LFU**: 페이지의 과거 총 참조 횟수를 카운트하는 방식
    - 페이지의 참조 횟수를 정확히 반영할 수 있다는 장점이 있지만, 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로 오버헤드가 상대적으로 크다.
- **구현 방법**
  - 연결 리스트를 사용하며, `O(N)`의 시간복잡도를 가진다.
  - 페이지들을 참조 횟수대로 연결 리스트에 나열하며, 앞쪽으로 갈 수록 참조 횟수가 적은 페이지고, 뒤쪽으로 갈 수록 참조 횟수가 많은 페이지다.
  - 새로운 페이지가 메모리에 적재되거나 기존에 있던 페이지가 다시 참조되면,
    - 연결 리스트 가장 앞에 있던 페이지를 디스크에 보낸다.
    - 새로운 또는 다시 참조된 페이지를 참조 횟수에 따라 연결 리스트에 적절히 재배치한다.
  - 최소 힙을 사용하여 페이지의 참조 횟수를 관리하면 `O(logN)`
 
### 클럭 알고리즘
<img width=500 src="https://github.com/user-attachments/assets/dc80e740-8315-422a-a0a4-fbb2e2e6dc1e">

- 페이지들의 참조 비트를 순차적으로 조사하여, 최근에 참조되지 않은 페이지를 교체하는 방식
- 하드웨어적인 지원을 이용해, LRU나 LFU 알고리즘에서 발생하는 소프트웨어적인 운영 오버헤드를 줄인다.
- 가장 오래전에 참조된 페이지를 교체하는 LRU와 달리, 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 않는다.
- **동작 원리**
  - 교체 대상 페이지를 찾기 위해 클럭 알고리즘은 메모리에 현재 올라와 있는 페이지의 참조 비트 정보를 시계 방향으로 따라가며 조사한다.
  - 시곗바늘이 가리키는 페이지의 참조 비트가 1인 경우, 클럭 알고리즘은 해당 비트를 0으로 바꾼 후 시곗바늘을 한 칸 진행시키고, 참조비트가 0인 페이지를 찾으면 그 페이지를 교체한다.
  - 참조 비트는 그 페이지가 참조 될 때 1로 자동 세팅되므로, 시곗바늘이 한 바퀴 돌아오는 동안에 다시 참조되지 않을 경우 그 페이지는 교체된다.
- 적어도 시곗바늘이 한 바퀴를 도는 데 소요되는 시간만큼 페이지를 메모리에 유지시켜줌으로써 페이지 부재율을 줄이도록 설계되었기 때문에 **2차 기회(Second chance Replacement, SCR) 알고리즘**이라고도 부른다.
- 대부분의 시스템에서 페이지 교체 알고리즘으로 클럭 알고리즘을 채택한다.

## 📌 스레싱(Thrashing)
<img width=500 src="https://github.com/user-attachments/assets/00305cd6-82e4-4e49-8279-1288c0b2cecf">

- 페이지 부재율 증가에 따라 잦은 페이지 교체로 인해 CPU 이용률이 떨어지는 문제   
  `프로세스가 실행되는 시간 < 페이징에 소요되는 시간`
    
- **스레싱이 발생하는 상황**
  - CPU의 이용률이 낮을 경우, 운영체제는 메모리에 적재된 프로세스의 수가 적다고 판단하여 그 수를 늘리게 된다. 즉, **멀티 프로그래밍의 정도(Multi-Programming Degree, MPD)**를 높인다.
    - **멀티 프로그래밍의 정도**: 메모리에서 동시에 실행되는 프로세스 수
  - MPD가 과도하게 높아지면 각 프로세스들이 사용할 수 있는 메모리의 양이 지나치게 감소한다.
  - 가용한 메모리 양이 감소하면, 프로세스들은 최소한의 프레임이 보장되지 않아 페이지 부재율이 높아진다.
  - 페이지 부재율이 높아지면 CPU 이용률은 급격히 떨어진다.
  - 운영체제는 CPU 이용률이 떨어지는 이유가 적은 프로세스 수라고 판단하여 MPD를 높이는데, 이로 인해 프로세스마다 할당되는 프레임의 수가 더 감소한다.
- 스레싱이 발생하지 않도록 하면서 CPU 이용률을 최대한 높일 수 있도록 멀티 프로그래밍 정도를 조절하는 것이 중요하다.
- 멀티 프로그래밍 정도를 조절해 CPU 이용률을 높이는 동시에 스레싱을 방지하는 방법에는 워킹 셋 알고리즘과 페이지 부재 빈도 알고리즘이 있다.

### 워킹 셋(Working Set) 알고리즘
<img width=500 src="https://github.com/user-attachments/assets/107debf3-1731-4ac2-b0ea-e28907f8e28c">


### 페이지 부재 빈도 알고리즘
<img width=500 src="https://github.com/user-attachments/assets/75ed3afb-0bd2-4393-a58d-dd080598359b">


## 🚧 페이지드 세그멘테이션
## 🚧 요구 페이징
## 🚧 프레임 할당 방식
